
# ğŸš€ Numba.OpenCL

> **VocÃª nÃ£o precisa de uma GPU de Ãºltima geraÃ§Ã£o para acelerar seus cÃ¡lculos!** 
> Transforme qualquer dispositivo compatÃ­vel com OpenCL em um acelerador para seus algoritmos Python.

## ğŸ” VisÃ£o Geral

O projeto `numba_opencl` Ã© uma extensÃ£o que emula a API `numba.cuda` usando PyOpenCL como backend. Isso permite que cÃ³digo existente escrito para GPUs NVIDIA usando `numba.cuda` possa ser facilmente adaptado para execuÃ§Ã£o em uma ampla variedade de dispositivos que suportam OpenCL, incluindo:

- ğŸ–¥ï¸ GPUs AMD e Intel
- ğŸ’» CPUs multi-core 
- ğŸ“± Dispositivos mÃ³veis compatÃ­veis
- ğŸ§  Aceleradores especializados

## âœ¨ Recursos Principais

- ğŸ”„ **API compatÃ­vel com CUDA**: Use a sintaxe familiar do `numba.cuda` com dispositivos OpenCL
- ğŸŒ **Portabilidade Universal**: Execute em qualquer dispositivo compatÃ­vel com OpenCL
- ğŸ”§ **Decoradores JIT**: Compile funÃ§Ãµes Python para kernels OpenCL com o decorador `@ocl.jit`
- ğŸ“Š **Gerenciamento de memÃ³ria**: TransferÃªncia eficiente de dados entre host e dispositivo
- âš¡ **Streams**: Suporte a execuÃ§Ã£o assÃ­ncrona para mÃ¡ximo desempenho
- ğŸ“ˆ **Profiling**: Ferramentas para anÃ¡lise e otimizaÃ§Ã£o de desempenho
- ğŸ”’ **FunÃ§Ãµes de sincronizaÃ§Ã£o**: Barreiras e operaÃ§Ãµes atÃ´micas para cÃ¡lculos seguros

## ğŸ“¦ InstalaÃ§Ã£o

```bash
pip install pyopencl numba numpy siphash24 prettytable
```

Ou instale diretamente da fonte:

```bash
git clone https://github.com/usuario/numba-opencl.git
cd numba-opencl
pip install -e .
```

## ğŸ“‚ Estrutura do Projeto

```
numba_opencl/
  â”œâ”€â”€ __init__.py     # Exporta os principais componentes
  â”œâ”€â”€ core.py         # ImplementaÃ§Ã£o principal do OpenCL
  â”œâ”€â”€ decorators.py   # OperaÃ§Ãµes atÃ´micas e sincronizaÃ§Ã£o
  â”œâ”€â”€ utils.py        # FunÃ§Ãµes utilitÃ¡rias
  â”œâ”€â”€ config.py       # Sistema de configuraÃ§Ã£o
  â””â”€â”€ profiler.py     # Ferramentas de profiling
main.py               # Exemplos e benchmarks
tests.py              # Testes automatizados
setup.py              # Script de instalaÃ§Ã£o
```

## ğŸš€ Uso BÃ¡sico

```python
import numpy as np
from numba_opencl import ocl

# Definir um kernel OpenCL
@ocl.jit
def vector_add(a, b, c):
    i = ocl.get_global_id(0)
    if i < len(c):
        c[i] = a[i] + b[i]

# Criar arrays
a = np.array([1, 2, 3, 4], dtype=np.float32)
b = np.array([10, 20, 30, 40], dtype=np.float32)
c = np.zeros_like(a)

# Transferir para o dispositivo
d_a = ocl.to_device(a)
d_b = ocl.to_device(b)
d_c = ocl.to_device(c)

# Executar kernel (similar ao CUDA)
vector_add(d_a, d_b, d_c, grid=(1,), block=(4,))

# Obter resultado
result = d_c.copy_to_host()
print(result)  # [11, 22, 33, 44]
```

## ğŸ”¥ Exemplos AvanÃ§ados

### ğŸ§® MultiplicaÃ§Ã£o de Matrizes

```python
import numpy as np
from numba_opencl import ocl

@ocl.jit
def matrix_multiply(a, b, c, width):
    row = ocl.get_global_id(0)
    col = ocl.get_global_id(1)

    if row < width and col < width:
        tmp = 0.0
        for i in range(width):
            tmp += a[row * width + i] * b[i * width + col]
        c[row * width + col] = tmp

# Criar matrizes
width = 32
a_mat = np.random.rand(width, width).astype(np.float32)
b_mat = np.random.rand(width, width).astype(np.float32)
c_mat = np.zeros((width, width), dtype=np.float32)

# Reformatar para array unidimensional
a_flat = a_mat.flatten()
b_flat = b_mat.flatten()
c_flat = c_mat.flatten()

# Transferir para o dispositivo
d_a = ocl.to_device(a_flat)
d_b = ocl.to_device(b_flat)
d_c = ocl.to_device(c_flat)

# Executar kernel
block_dim = (16, 16)
grid_dim = (width // block_dim[0] + 1, width // block_dim[1] + 1)
matrix_multiply(d_a, d_b, d_c, width, grid=grid_dim, block=block_dim)

# Obter resultado
result_flat = d_c.copy_to_host()
result_mat = result_flat.reshape((width, width))
```

### âš¡ Usando Streams para ExecuÃ§Ã£o AssÃ­ncrona

```python
import numpy as np
from numba_opencl import ocl

@ocl.jit
def vector_add(a, b, c):
    i = ocl.get_global_id(0)
    if i < len(c):
        c[i] = a[i] + b[i]

# Criar streams
stream1 = ocl.stream()
stream2 = ocl.stream()

# Executar kernels em streams diferentes
with stream1:
    vector_add(d_a1, d_b1, d_c1, grid=grid_size, block=block_size)

with stream2:
    vector_add(d_a2, d_b2, d_c2, grid=grid_size, block=block_size)

# Sincronizar
stream1.synchronize()
stream2.synchronize()
```

### ğŸ“Š Usando o Profiler

```python
from numba_opencl.profiler import profiler

# Ativar profiling
profiler.start()

# Execute seus kernels
vector_add(d_a, d_b, d_c, grid=grid_size, block=block_size)
matrix_multiply(d_a, d_b, d_c, width, grid=grid_dim, block=block_dim)

# Imprimir estatÃ­sticas
profiler.print_stats()

# Parar profiling
profiler.stop()
```

## ğŸ–¥ï¸ GestÃ£o de Dispositivos

```python
from numba_opencl import ocl

# Listar dispositivos disponÃ­veis
devices = ocl.list_devices()
for device in devices:
    print(f"ID: {device['id']}, Nome: {device['name']}, Tipo: {device['type']}")

# Selecionar dispositivo especÃ­fico
ocl.select_device(0)  # Selecionar pelo ID

# Selecionar por tipo
ocl.select_device_by_type('GPU')  # ou 'CPU' ou 'ACCELERATOR'

# Obter informaÃ§Ãµes do dispositivo atual
info = ocl.get_device_info()
print(f"Dispositivo atual: {info['name']} ({info['type']})")
```

## ğŸ“š API

### ğŸ› ï¸ Principais Classes e FunÃ§Ãµes

#### ğŸ”§ ConfiguraÃ§Ã£o e InicializaÃ§Ã£o

- `ocl.list_devices()`: Lista todos os dispositivos OpenCL disponÃ­veis
- `ocl.select_device(device_id)`: Seleciona um dispositivo pelo ID
- `ocl.select_device_by_type(device_type)`: Seleciona um dispositivo pelo tipo
- `ocl.get_device_info(device_id=None)`: Retorna informaÃ§Ãµes do dispositivo
- `ocl.print_device_info()`: Imprime informaÃ§Ãµes detalhadas do dispositivo atual
- `ocl.auto_select_best_device()`: Seleciona automaticamente o melhor dispositivo disponÃ­vel

#### ğŸš€ CompilaÃ§Ã£o e ExecuÃ§Ã£o

- `ocl.jit(func)`: Decorator para compilar uma funÃ§Ã£o Python em um kernel OpenCL
- `ocl.synchronize()`: Sincroniza todos os comandos pendentes
- `ocl.device_count()`: Retorna o nÃºmero de dispositivos OpenCL disponÃ­veis
- `ocl.compile_program(source)`: Compila um programa OpenCL diretamente do cÃ³digo-fonte

#### ğŸ§µ FunÃ§Ãµes de Grid/Thread

- `ocl.get_global_id(dim)`: ObtÃ©m o ID global da thread atual
- `ocl.get_local_id(dim)`: ObtÃ©m o ID local da thread
- `ocl.get_group_id(dim)`: ObtÃ©m o ID do grupo de trabalho
- `ocl.get_local_size(dim)`: ObtÃ©m o tamanho local do grupo
- `ocl.get_global_size(dim)`: ObtÃ©m o tamanho global
- `ocl.get_num_groups(dim)`: ObtÃ©m o nÃºmero de grupos de trabalho

#### ğŸ’¾ Gerenciamento de MemÃ³ria

- `ocl.to_device(array)`: Transfere um array NumPy para o dispositivo
- `ocl.device_array(shape, dtype)`: Cria um array vazio no dispositivo
- `ocl.device_array_like(array)`: Cria um array vazio com a mesma forma e tipo
- `ocl.shared_array(shape, dtype)`: Cria um array na memÃ³ria compartilhada
- `ocl.pinned_array(shape, dtype)`: Cria um array em memÃ³ria "pinned" para transferÃªncias mais rÃ¡pidas
- `ocl.managed_array(shape, dtype)`: Cria um array gerenciado (simulado)

#### ğŸ“Š DeviceArray

- `DeviceArray.copy_to_host()`: Copia dados do dispositivo para o host
- `DeviceArray.copy_to_device(array)`: Copia dados do host para o dispositivo
- `DeviceArray.copy_from_device(device_array)`: Copia de outro array do dispositivo
- `DeviceArray.copy_from_device_async(device_array, stream)`: CÃ³pia assÃ­ncrona
- `DeviceArray.zero_copy_view()`: Retorna uma visualizaÃ§Ã£o de zero-cÃ³pia (quando disponÃ­vel)

#### âš¡ Streams

- `ocl.stream()`: Cria um novo stream
- `stream.synchronize()`: Sincroniza operaÃ§Ãµes no stream
- `stream.wait_event(event)`: Aguarda um evento
- `stream.add_callback(callback)`: Adiciona uma funÃ§Ã£o de callback para ser chamada apÃ³s a conclusÃ£o

#### ğŸ“ˆ Profiling

- `profiler.start()`: Inicia o profiling
- `profiler.stop()`: Para o profiling
- `profiler.get_stats(kernel_name=None)`: ObtÃ©m estatÃ­sticas de execuÃ§Ã£o
- `profiler.print_stats()`: Imprime estatÃ­sticas formatadas
- `profiler.export_chrome_trace(filename)`: Exporta dados de perfil no formato Chrome Tracing
- `profiler.reset()`: Limpa todos os dados de perfil coletados

### ğŸ”„ OperaÃ§Ãµes AtÃ´micas e SincronizaÃ§Ã£o

- `atomic_add(array, index, value)`: AdiÃ§Ã£o atÃ´mica
- `atomic_max(array, index, value)`: MÃ¡ximo atÃ´mico
- `atomic_min(array, index, value)`: MÃ­nimo atÃ´mico
- `atomic_cas(array, index, compare_value, value)`: Compare-and-swap
- `atomic_exch(array, index, value)`: Troca atÃ´mica
- `atomic_inc(array, index)`: Incremento atÃ´mico
- `atomic_dec(array, index)`: Decremento atÃ´mico
- `barrier()`: Barreira de sincronizaÃ§Ã£o global
- `local_barrier()`: Barreira local dentro de um grupo
- `syncthreads()`: Alias para local_barrier() (compatibilidade CUDA)
- `mem_fence(flags)`: Barreira de memÃ³ria com flags especÃ­ficas

## ğŸ§ª Exemplos IncluÃ­dos

O arquivo `main.py` contÃ©m vÃ¡rios exemplos:

1. **ğŸ”¢ Soma de Vetores**: OperaÃ§Ã£o bÃ¡sica de elemento a elemento
2. **ğŸ§® MultiplicaÃ§Ã£o de Matrizes**: DemonstraÃ§Ã£o de kernel 2D
3. **ğŸ–¼ï¸ Filtro de Imagem**: Exemplo de processamento de imagem (blur)
4. **ğŸ“Š ReduÃ§Ã£o**: Soma de todos os elementos de um array
5. **ğŸ“ˆ SAXPY**: OperaÃ§Ã£o Single-Precision A*X Plus Y
6. **ğŸ” ConvoluÃ§Ã£o 2D**: AplicaÃ§Ã£o de filtro Sobel para detecÃ§Ã£o de bordas

## âš¡ Benchmarks

O projeto inclui benchmarks que comparam o desempenho do OpenCL versus NumPy puro:

```bash
python main.py --bench
```

Os benchmarks incluem:
- ğŸ”¢ Soma de vetores
- ğŸ§® MultiplicaÃ§Ã£o de matrizes
- ğŸ“Š ReduÃ§Ã£o (soma)
- ğŸ“ˆ SAXPY
- ğŸ” ConvoluÃ§Ã£o 2D

## ğŸ§ª Testes

O arquivo `tests.py` contÃ©m testes automatizados:

```bash
python tests.py
```

## ğŸ”„ Compatibilidade

Esta biblioteca foi testada com:
- Python 3.6+
- NumPy 1.20+
- PyOpenCL 2022.1+
- Numba 0.55+

Dispositivos testados:
- ğŸŸ¢ GPUs NVIDIA (versÃµes de driver 470+)
- ğŸ”´ GPUs AMD (drivers ROCm e proprietÃ¡rios)
- ğŸ”µ GPUs Intel
- ğŸ’» CPUs Intel/AMD via OpenCL

## âš ï¸ LimitaÃ§Ãµes

- Esta Ã© uma implementaÃ§Ã£o de prova de conceito
- NÃ£o Ã© uma integraÃ§Ã£o completa com o compilador Numba
- A traduÃ§Ã£o Python para OpenCL C Ã© simplificada
- O suporte a tipos complexos Ã© limitado
- Sem suporte para CUDA Unified Memory
- Alguns padrÃµes de programaÃ§Ã£o CUDA avanÃ§ados nÃ£o sÃ£o suportados

## ğŸ’¡ Por que usar numba_opencl?

- ğŸš« **NÃ£o exige hardware NVIDIA**: Utilize o hardware que vocÃª jÃ¡ possui
- ğŸ’° **Economia**: Evite o custo de GPUs dedicadas caras
- ğŸ”„ **CÃ³digo portÃ¡vel**: Escreva uma vez, execute em qualquer lugar
- ğŸ§  **Aproveite a CPU**: Mesmo sem GPU, acelere seu cÃ³digo usando todos os nÃºcleos da CPU
- ğŸŒ± **Aprendizado simplificado**: Use a sintaxe familiar do CUDA com seu hardware atual

## ğŸ‘¥ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, abra um issue ou envie um pull request.

## ğŸ“„ LicenÃ§a

MIT
